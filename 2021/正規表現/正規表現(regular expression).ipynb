{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fantastic-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lonely-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = [v for v,k,t in os.walk('./')]\n",
    "kk = [k for v,k,t in os.walk('./')]\n",
    "tt = [t for v,k,t in os.walk('./')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imported-hacker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zips = [os.path.join(vv[0],i) for i in tt[0] if os.path.splitext(i)[-1] == '.zip']\n",
    "zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chinese-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zips:\n",
    "    with zipfile.ZipFile(i) as myzip:\n",
    "#         print(myzip.filename) # zipファイル名の表示\n",
    "        newfilepath = myzip.filename.split('.zip')[0]\n",
    "        if os.path.isdir(newfilepath):\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(newfilepath)\n",
    "        for name in myzip.infolist(): #解压文件\n",
    "            name.filename = name.filename.encode('cp437').decode('gbk')\n",
    "            myzip.extract(name,newfilepath)\n",
    "        myzip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-tower",
   "metadata": {},
   "source": [
    "### Day01　function overview\n",
    "- 内容抽出\n",
    "- 文字列の分割\n",
    "- 文字列の入れ替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "neither-split",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['「殺したのは母」', '「居場所を知っているのでは」', '「うそ泣き」']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 「」内のすべての内容を抽出\n",
    "s = '''\n",
    "だが、とも子さんが事件を起こしたような言葉がネット上で目立つようになった。「殺したのは母」「居場所を知っているのでは」。記者の前で涙を見せた場面が報じられると「うそ泣き」と言われた。とも子さんを疑うコメントをした男女が自宅近くで遊ぶ長女（11）に話しかけ、その様子をSNSに投稿したこともあった。外に出るのが怖くなった。\n",
    "'''\n",
    "re.findall('(「.*?」)', s) # 将正则表达式作为字符串传入到第1个参数，将原始字符串作为第2个参数传入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confident-joyce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nだが',\n",
       " 'とも子さんが事件を起こしたような言葉がネット上で目立つようになった',\n",
       " '「殺したのは母」「居場所を知っているのでは」',\n",
       " '記者の前で涙を見せた場面が報じられると「うそ泣き」と言われた',\n",
       " 'とも子さんを疑うコメントをした男女が自宅近くで遊ぶ長女（11）に話しかけ',\n",
       " 'その様子をSNSに投稿したこともあった',\n",
       " '外に出るのが怖くなった',\n",
       " '\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 句読点などをもとに、文字列を分割する\n",
    "re.split('[、。]+',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "becoming-necessity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nだが|とも子さんが事件を起こしたような言葉がネット上で目立つようになった|「殺したのは母」「居場所を知っているのでは」|記者の前で涙を見せた場面が報じられると「うそ泣き」と言われた|とも子さんを疑うコメントをした男女が自宅近くで遊ぶ長女（11）に話しかけ|その様子をSNSに投稿したこともあった|外に出るのが怖くなった|\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# すべての読点、または句点。を|に入れ代わる\n",
    "re.sub('[、。]+','|',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-coast",
   "metadata": {},
   "source": [
    "### Day1练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "painful-mobile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3123123', '32132', '3213213', '3213123']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将'3123123-32132-3213213-3213123'中被'-'分隔的片段提取出来\n",
    "a = '3123123-32132-3213213-3213123'\n",
    "a.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brutal-entrance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'渝中、江北、黔江、荣昌、秀山'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将'渝中区、江北区、黔江县、荣昌区、秀山县'中的地名去掉区、县后缀后提取出来\n",
    "b = '渝中区、江北区、黔江县、荣昌区、秀山县'\n",
    "# re.sub(r'区|县','',b)\n",
    "re.sub(r'[区县]','',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "qualified-investor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n“十四五”规划编制工作开展网上意见征求，欢迎建言  \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "将'<a href=\"https://news.163.com/20/0823/20/FKO84J73000189FH.html\">\n",
    "“十四五”规划编制工作开展网上意见征求，欢迎建言  </a>'中的中文内容提取出来\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "c = '''\n",
    "<a href=\"https://news.163.com/20/0823/20/FKO84J73000189FH.html\">“十四五”规划编制工作开展网上意见征求，欢迎建言  </a>\n",
    "'''\n",
    "soup = BeautifulSoup(c, 'html.parser')\n",
    "soup.text\n",
    "\n",
    "#或者\n",
    "# re.findall(r'<a.*?>(.*?)</a>',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jewish-customs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['960', '15']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "针对'body {\n",
    "    font-family: \"Microsoft YaHei\", sans-serif;\n",
    "    min-width: 960px;\n",
    "    background: rgb(255, 255, 255);\n",
    "    font-size: 15px;\n",
    "}'，将所有'px'之前的数值提取出来\n",
    "\n",
    "'''\n",
    "d = '''\n",
    "body {\n",
    "    font-family: \"Microsoft YaHei\", sans-serif;\n",
    "    min-width: 960px;\n",
    "    background: rgb(255, 255, 255);\n",
    "    font-size: 15px;\n",
    "}'\n",
    "'''\n",
    "re.findall(r'(\\d+)px', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-twelve",
   "metadata": {},
   "source": [
    "### Day2 \n",
    "- 绝大部分单个字符都可以用来匹配其本身，即我们的正则表达式中写的是什么内容，就直截了当地匹配对应地字符串片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "directed-holder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', 'b', 'b', 'b', 'b', 'b']\n",
      "['bb', 'bb', 'bb']\n",
      "['bbb', 'bbb']\n"
     ]
    }
   ],
   "source": [
    "s = 'aaabbbbbbaaa'\n",
    "\n",
    "# 匹配1个b的模式并提取出来\n",
    "print(re.findall('b', s))\n",
    "\n",
    "# 匹配2个连续b的模式并提取出来\n",
    "print(re.findall('bb', s))\n",
    "\n",
    "# 匹配3个连续b的模式并提取出来\n",
    "print(re.findall('bbb', s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-conference",
   "metadata": {},
   "source": [
    "- 但正则表达式为了实现更通用地字符模式匹配，衍生出了特定的一类特殊的单个字符，即**元字符（metacharacters）**\n",
    "- 这些元字符在正则表达式中起着特殊的作用，因此直接用其来匹配他们自己是无效的,比如`'.'`:\n",
    "    - 对于**元字符**的匹配，我们需要在其之前添加`'\\'`来对其进行转义，才能匹配它本身代表的字符\n",
    "    - 正则表达式中全部的元字符有如下\n",
    "    |1|2|3|4|5|6|7|8|9|10|11|12|13|\n",
    "    |-|-|-|-|-|-|-|-|-|-|-|-|-|\n",
    "    |^|$|*|+|?|{|}|[|]|\\\\|\\||(|)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "early-transcript",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'a', '.', '.', '.', 'a', 'a', 'a']\n",
      "['.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "s = 'aaa...aaa'\n",
    "\n",
    "# 直接传入.来匹配自身是无效的\n",
    "print(re.findall('.', s))\n",
    "#添加'\\'给以转义\n",
    "print(re.findall('\\.',s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-trail",
   "metadata": {},
   "source": [
    "### Day2 练习\n",
    "- 下面请你从下面的目标字符串target中提取所有的`'${|'`片段："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "negative-stress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$', '{', '|', '$', '{', '|', '$', '{', '|']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'abcd${|ABC${|D.3213${|\\dsaddas'\n",
    "re.findall(r'[\\$\\{\\|]',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-outreach",
   "metadata": {},
   "source": [
    "### Day3\n",
    "- 如果想要匹配的字符模式中存在不确定的其他字符,就需要用到`.`\n",
    "- 1个`.`代表任意不为换行符的字符出现一次，2个连续的`.`就代表两个连续汉字\n",
    "- `+`代表前面最近的模式出现**1次或以上**\n",
    "- `.+`就代表任意不为换行符的字符出现至少1次\n",
    "- `*`代表前面最近的模式出现**0次或以上**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indian-anatomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['重庆市渝北区']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s = '重庆市渝北区'\n",
    "\n",
    "re.findall('..市..区', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "central-dubai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['成都市天府新区']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#匹配2字的成都和3字的天府新\n",
    "s = '成都市天府新区'\n",
    "re.findall('.+市.+区',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "declared-tobacco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['哈尔滨市道口区'], ['江北区'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#不止想要匹配带有XX市前缀的结果，如果只有XX区，前面没有市的信息也是可以匹配的\n",
    "s1 = '哈尔滨市道口区'\n",
    "s2 = '江北区'\n",
    "re.findall('.*市*.+区',s1),re.findall('.*市*.+区',s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-frost",
   "metadata": {},
   "source": [
    "### Day3 练习\n",
    "- 从给定的字符串中提取出所有完整的英文人名，即你的正则应当匹配到`布莱特·拉特纳`和`克里斯汀·诺兰`，而其它字符串匹配结果应为空列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arranged-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['布莱特·拉特纳'], ['克里斯汀·诺兰']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = ['布莱特·拉特纳', '成龙', '克里斯汀·诺兰', '·托马斯']\n",
    "result = []\n",
    "for s in ss:\n",
    "    match_result = re.findall('布.*|克.*',s)\n",
    "    if match_result == []:\n",
    "        pass\n",
    "    else:\n",
    "        result.append(match_result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "secondary-lease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['布莱特·拉特纳'], [], ['克里斯汀·诺兰'], []]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果保留空列表\n",
    "ss = ['布莱特·拉特纳', '成龙', '克里斯汀·诺兰', '·托马斯']\n",
    "result = []\n",
    "for s in ss:\n",
    "    match_result = re.findall('.+·.+',s)\n",
    "#     match_result = re.findall('布.*|克.*',s)\n",
    "    result.append(match_result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-engine",
   "metadata": {},
   "source": [
    "### Day4 ：`[]`的用法\n",
    "- 用于范围匹配：我们要匹配的内容为同一类型字符的连续出现\n",
    "- `[]`的作用是匹配括起来的内容里各种模式中的任意一种\n",
    "- `[]`还可以通过`-`符号连接两个字符串来概括中间范围内的字符\n",
    "    - 因此我们可以在`[]`里简短地概括范围，\n",
    "        - 比如`[0-9]`就代表**从0到9**的所有字符\n",
    "        - `[a-z]`就代表从`a`到`z`的所有小写字母，\n",
    "        - `[A-Z]`就代表从`A`到`Z`的所有大写字母："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "constant-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['67876', '78878']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '1111678762222788781111'\n",
    "\n",
    "#匹配所有的6或者7或者8\n",
    "re.findall('[678]',s1)\n",
    "\n",
    "#匹配上述3种字符任意排列形成的连续片段\n",
    "re.findall('[678]+',s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "proud-bridges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '1', '3', '1', '2', '3', '2', '1', '3', '2', '1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[0-9]','adsad21312dasdas321321')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "enabling-inside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', 'A', 'b', 'n', 'B', 'V', 'f', 'a', 'B', 'v']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[a-zA-Z]', '321312SAbnBVfaBv4545746')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "foster-sleep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13511111111', '010', '11111111', '13922222222', '13300000000']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对用户名与文本交替构成的字符串匹配所有电话号码并进行提取\n",
    "s = '张三：13511111111，李四：010-11111111，王五：13922222222，赵六：13300000000'\n",
    "re.findall('[0-9]+',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "british-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13511111111', '010-11111111', '13922222222', '13300000000']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#观察到含`-`符号的电话号码被分成了2各部门，因此可以把`-`符号也放到[]里\n",
    "s = '张三：13511111111，李四：010-11111111，王五：13922222222，赵六：13300000000'\n",
    "re.findall('[0-9-]+',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-attribute",
   "metadata": {},
   "source": [
    "### Day4 练习\n",
    "- 从给定的字符串中提取出所有正确的满足日期格式（XXXX-XX-XX）格式的片段："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "educational-institution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-08-27', '2020-08-25']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '今天是-2020-08-27，天气晴，比前天（2020-08-25-）要凉快了一些。'\n",
    "[i.strip('-') for i in re.findall('[0-9-]+',target)]\n",
    "#strip可去除首位指定字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alternative-caribbean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-08-27', '2020-08-25']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '今天是-2020-08-27，天气晴，比前天（2020-08-25-）要凉快了一些。'\n",
    "re.findall('[0-9]+-[0-9]+-[0-9]+',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-species",
   "metadata": {},
   "source": [
    "### Day5\n",
    "- `{}`类似之前的`*`和`+`，都是对之前的模式进行次数上的修饰\n",
    "- 主要有三种使用格式。\n",
    "    - 1.`{m}`的格式，`m`是整数，代表着前面的模式出现恰好m次\n",
    "    - 2.`{m,n}`的格式，代表着所修饰的模式最少出现`m`次，最多出现`n`次，更加灵活\n",
    "        - 注意，在使用`{m,n}`方式提取目标字符的时候正则表达式会误把长度超过n的单词的前几位截断下来当成满足要求的结果。参考day4 example\n",
    "    - 3.`{m,}`，即`n`可以空着不写，这样代表匹配连续出现`m`次以及以上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "antique-coordinator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cccc']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ay4 example\n",
    "re.findall('[a-z]{3,5}', 'aaaaaa bbbbbb cccc')\n",
    "\n",
    "#这种情况可以结果列表推导来配合正则完成\n",
    "[word for word in re.findall('[a-z]{3,}', 'aaaaaa bbbbbb cccc') if len(word) <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cooked-overhead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['500000', '500100', '500101', '500102', '110101', '110102']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '1 重庆市 500000 2 重庆市市辖区 500100 3 重庆市万州区 500101 4 重庆市涪陵区 500102 5 北京市东城区：110101 6 北京市西城区：110102'\n",
    "#匹配行政区划代码\n",
    "#通过查阅相关资料得知，行政区划代码是由**6位**阿拉伯数字组成\n",
    "re.findall('[0-9]{6}',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "earned-concentrate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123456', '1234567']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#匹配所有长度大于等于5且小于等于8的连续数字片段\n",
    "s = 'A:123456 B:1234 C:1234567 D:12'\n",
    "re.findall('[0-9]{5,8}',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bound-hudson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123456', '1234', '1234567']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#匹配所有出现次数3次及以上的连续数字\n",
    "s = 'A:123456 B:1234 C:1234567 D:12'\n",
    "re.findall('[0-9]{3,}',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-consensus",
   "metadata": {},
   "source": [
    "### Day5练习\n",
    "- 提取所有长度在3到8之间的大写字母开头的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "infrared-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The'],\n",
       " [],\n",
       " ['Regular'],\n",
       " [],\n",
       " ['Called'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Textual'],\n",
       " [],\n",
       " [],\n",
       " ['Patterns'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Distinct'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'The phrase Regular expressions, also Called regexes, is often used to mean the Specific, standard Textual syntax for Representing Patterns for matching text, as Distinct from the Mathematical notation Described below. '\n",
    "[re.findall('[A-Z][a-z]{2,7}',i) for i in target.split() if len(i) <= 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-average",
   "metadata": {},
   "source": [
    "### Day6\n",
    "- 处理`匹配字符串里所有夹在小写字母之间的连续数字内容`\n",
    "    - 1.可以使用`()`来圈定**子表达式**范围，它帮助我们告诉正则表达式在整个正则匹配到的片段中，我们真正需要返回的内容在哪些地方，`()`标记了一个子表达式的开始和结束位置。\n",
    "    - 2.在一个正则表达式中，可以利用`()`圈定出多个子表达式，进而实现成对，成组匹配结果的返回。每一组匹配内容形成了元组。\n",
    "    - 3.使用`re.match`的话，被标记的每个子表达式会依次对应每一个分组。调用`group`方法传入分组的索引即可获取提取的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "british-rough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd000ads', 'ada00012dad']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n这种方式只是把符合模式设定的字符串匹配到了，没有把连续数字部分提取出来。\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'abcd000ads  90  ad00  90ad ada00012dad'\n",
    "# 按照之前日程所学知识利用正则找到对应模式\n",
    "print(re.findall('[a-z]+[0-9]+[a-z]+', s))\n",
    "\n",
    "'''\n",
    "这种方式只是把符合模式设定的字符串匹配到了，没有把连续数字部分提取出来。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "needed-american",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000', '00012']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.将中间的连续数字部分用()圈定\n",
    "re.findall('[a-z]+([0-9]+)[a-z]+', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "rolled-academy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key1', 'value2'), ('key2', 'value2'), ('key3', 'value3')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.成对，成组实现\n",
    "s = 'a = {\"key1\": \"value2\", \"key2\": \"value2\", \"key3\": \"value3\"}'\n",
    "re.findall('\"(.*?)\": \"(.*?)\"',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "white-pollution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 'c', 'c')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '[[1, 2, 3], [a, b, 1], [1, a, 1], [c, c, c]]'\n",
    "re.findall('\\[([a-z]+), ([a-z]+), ([a-z]+)\\]',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "banned-fault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello 1234567 World\n",
      "1234567\n",
      "(0, 19)\n"
     ]
    }
   ],
   "source": [
    "# re.match\n",
    "content = 'Hello 1234567 World_This is a Regex Demo'\n",
    "print(re.match('^Hello\\s(\\d+)\\sWorld',content).group())\n",
    "print(re.match('^Hello\\s(\\d+)\\sWorld',content).group(1))\n",
    "print(re.match('^Hello\\s(\\d+)\\sWorld',content).span())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-conditions",
   "metadata": {},
   "source": [
    "### Day6练习\n",
    "- 在下面的字符串中匹配出形式如(时间跨度，节气)的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "accurate-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2月3-4日', '立春'),\n",
       " ('2月18-19日', '雨水'),\n",
       " ('3月5-6日', '惊蛰'),\n",
       " ('3月20-21日', '春分'),\n",
       " ('12月21-23日', '冬至')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '2月3-4日对应节气为立春，2月18-19日对应节气为雨水，3月5-6日对应节气为惊蛰，3月20-21日对应节气为春分，12月21-23日对应节气为冬至。'\n",
    "re.findall('(.*?[0-9]+-[0-9]+日).*?节气为(.*?)[，。]',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-promotion",
   "metadata": {},
   "source": [
    "### Day7 `?`的用法\n",
    "- 1.修饰之前的子模式，将其从贪婪模式到非贪婪模式\n",
    "- 2.可以和`*``+`一样充当范围修饰的作用\n",
    "    - 其意义是 **`匹配之前模式对应的内容0次或1次`**，也有非贪婪的思想在其中\n",
    "- 3.非贪婪匹配的写法：`.*?`\n",
    "    - 贪婪匹配是尽可能匹配多的字符，非贪婪匹配就是尽可能匹配少的字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abandoned-applicant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "假设想要匹配出所有成对的中括号所包裹的内容以及括号本身，\n",
    "即得到结果：'[1, 2, 3]', '[4, 5, 6]', '[7, 8, 9]', '[10, 11, 12]'\n",
    "\n",
    "但是按照之前的写法：\n",
    "'''\n",
    "s  = '[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]'\n",
    "re.findall('\\[.*\\]',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-conjunction",
   "metadata": {},
   "source": [
    "- 可以看到匹配到的结果把所有中括号的内容合并成一个全部提取出来了。\n",
    "    - 这是因为`正则表达式`中默认`*``+`等范围修饰符都是贪婪的，即**`优先输出满足条件的结果中最长的那个`**\n",
    "    - 这种时候就需要用到`？`的主要功能：修饰之前的子模式，将其从贪婪模式到非贪婪模式\n",
    "    - `?`在网页爬虫书写提取内容的正则表达式时很常用。\n",
    "    - 在做匹配的时候，**字符串中间**尽量使用**非贪婪匹配**，也就是用`.*?`来代替`.*`,以免出现匹配结果缺失的情况\n",
    "    - 如果匹配的结果在**字符串结尾**，`.*?`就有可能匹配不断哦任何内容了，因为它会匹配尽可能少的字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "broad-rapid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1, 2, 3]', '[4, 5, 6]', '[7, 8, 9]', '[10, 11, 12]']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\[.*?\\]', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "straight-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "贪婪模式: ['<div><a>测试<br></a></div>']\n",
      "非贪婪模式: ['<div>', '测试', '</a>']\n",
      "获取非标签部分的内容： ['测试']\n"
     ]
    }
   ],
   "source": [
    "# 需要提取所有成对标签中夹着的内容，可以对比贪婪模式与非贪婪模式的区别\n",
    "s = '<div><div><a>测试<br></a></div></div>'\n",
    "\n",
    "print('贪婪模式:',re.findall('>(.+)<',s))\n",
    "print('非贪婪模式:',re.findall('>(.+?)<',s))\n",
    "print('获取非标签部分的内容：',[_ for _ in re.findall('>(.+?)<',s) if '<' not in _])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "completed-outdoors",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1', 'B', 'C2', 'D', 'E3']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#`？`的用法2\n",
    "'''\n",
    "匹配下面文本中的所有1个大写字母+1个数字 或 1个大写字母 的模式\n",
    "即后面紧跟着需不需要是数字无所谓\n",
    "'''\n",
    "s = 'A1 B C2 D E33'\n",
    "\n",
    "re.findall('[A-Z][0-9]?',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "provincial-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "1234567\n"
     ]
    }
   ],
   "source": [
    "# 非贪婪匹配\n",
    "'''\n",
    "这种情况的时候，`.*`后面是`\\d+`，也就是至少一个数字，\n",
    "因此`.*`就尽可能匹配多的字符，\n",
    "这里就把`123456`一起匹配到前面，给`\\d+`只留下一个可满足条件的数字`7`\n",
    "\n",
    "'''\n",
    "content = 'Hello 1234567 World_This is a Regex Demo'\n",
    "print(re.match('^He.*(\\d+).*Demo$',content).group(1))\n",
    "\n",
    "'''\n",
    "当`.*?`匹配到Hello后面的空白字符时，再往后的字符就是数字了，\n",
    "而`\\d`恰好可以匹配，那么`.*?`就不再进行匹配，交给`\\d+`去匹配后面的数字。\n",
    "这样`.*?`匹配了尽可能少的字符，`\\d+`的匹配结果就是1234567了\n",
    "'''\n",
    "print(re.match('^He.*?(\\d+).*Demo$',content).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "incident-flash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 'kEraCN')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非贪婪使用在字符串结尾\n",
    "content = 'http://weibo.com/comment/kEraCN'\n",
    "result1 = re.match('http.*?comment/(.*?)',content)\n",
    "result2 = re.match('http.*?comment/(.*)',content)\n",
    "\n",
    "result1.group(1),result2.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-maker",
   "metadata": {},
   "source": [
    "### Day7 练习\n",
    "- 下面是豆瓣电影上关于《新阴阳魔界2》的某条影评，请你观察规律，`提取出每一集的名称`，譬如`SE1 心灵感应 颅内连麦网恋 女主诱导男主杀自己丈夫获得解脱`对应的集名为`心灵感应`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "still-merit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 心灵感应', ' 虚拟世界', ' 灵魂转移', ' 魔力硬币', ' 校园故事', ' 小镇模型']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '''SE1 心灵感应 颅内连麦网恋 女主诱导男主杀自己丈夫获得解脱\n",
    "SE2 虚拟世界 当你努力一辈子终于获得你想要的成功 却突然发你所在的世界不是真实的你会怎么办\n",
    "SE3 灵魂转移 郁郁不得志的男主怀疑女朋友因为自己的落魄要离开自己 怀疑她劈腿 去抢银行结果发现自己的灵魂可以自由穿梭于别人的皮囊 最终他失去了自己的躯壳 在女朋友劈腿对象的皮囊中存在\n",
    "SE4 魔力硬币 带给持有人获得无尽掌声的buff 最后确实一场姐妹相伴的大戏 人心真的不要太贪婪 以及理智追星\n",
    "SE5 校园故事 拥有超能力但被自己超能力禁锢内心孤独的女孩 召唤朋友最后还是BE的故事\n",
    "SE8 小镇模型 上帝之手 这个能力可以有'''\n",
    "\n",
    "# re.findall('SE[0-9] (.+?) .*?',target)\n",
    "# re.findall('SE[0-9]+\\s+(.*?)\\s+',target)\n",
    "re.findall('\\d+(.+?)\\s',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-training",
   "metadata": {},
   "source": [
    "### Day8 `^`和 `$`的用法\n",
    "- `^`有点像`?`，按照使用方式的差异具有截然不同的两种功能\n",
    "    - 1.**`匹配字符串开头位置`**的功能\n",
    "    - 2.**`反选模式集合`**\n",
    "        - 只要在`[]`中把`^`置于第一个位置，就可以排除掉`[]`里的模式\n",
    "- `$`是与`^`功能相反，其功能是**`匹配结尾位置`**，对应的是要写到整个正则表达式的最后面\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "material-hearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['666', '777', '876', '323']\n",
      "['666']\n",
      "['CPD']\n"
     ]
    }
   ],
   "source": [
    "#对下面的字符串s，我们想匹配连续3个出现的数字\n",
    "s = '666 adas777 asdsa 876 323d ——'\n",
    "\n",
    "print(re.findall('[0-9]{3}',s))\n",
    "\n",
    "#匹配开头位置\n",
    "'''\n",
    "因为设置了`^`，对正则表达式开头的模式限定了必须从原始字符串开头位置进行匹配，\n",
    "所以恰巧满足条件又在原始字符串开头位置的666作为唯一结果得以输出\n",
    "'''\n",
    "print(re.findall('^[0-9]{3}',s))\n",
    "\n",
    "s1 = 'AAA ds 32 das  1221 CPD'\n",
    "print(re.findall('[A-Z]{3}$',s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "temporal-extension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['q', 'w', 'w', 'w', 'q', 'w', 'q']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.反选模式集合\n",
    "'''\n",
    "对于下面的字符串s，假如我们想要匹配到所有不为e、h、m的小写字母\n",
    "'''\n",
    "s = 'qwewwqhewqm'\n",
    "re.findall('[^ehm]',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-filter",
   "metadata": {},
   "source": [
    "### Day8 练习\n",
    "- 请你从下面的列表中提取检查所有的字符串元素是否在开头位置不为服并且结尾位置不为局的字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mineral-satin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['派出所', '监督委员会']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = ['国税局', '公安局', '派出所', '服务中心', '水利局', '气象局', '监督委员会']\n",
    "results = []\n",
    "for i in target:\n",
    "    if not re.findall('[服].*|.*[局]',i):\n",
    "        results.append(i)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "headed-apartment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['派出所', '监督委员会']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#别人的答案\n",
    "target = ['国税局', '公安局', '派出所', '服务中心', '水利局', '气象局', '监督委员会']\n",
    "\n",
    "[s for s in target if re.findall('^[^服]+[^局]$',s) != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-papua",
   "metadata": {},
   "source": [
    "### Day9 `|`的用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "textile-crystal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['434', 'ABCDE', '898']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "假如我们想提取目标字符串中夹在_之间的连续3个数字或连续5个大写字母\n",
    "'''\n",
    "s = '_434_ _ABCD_ _ABCDE_ _898_'\n",
    "re.findall('_([0-9]{3}|[A-Z]{5})_',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-gibraltar",
   "metadata": {},
   "source": [
    "### Day9 练习\n",
    "- 下面是东方财富某个页面记录的多种指数数据表背后的网页源代码，请你必须使用到`|`，从中提取出所有在`>`与`<`之间的，格式满足`xxx万`和`xxx亿`的片段，并根据结尾万和亿的区别将其转换为实际数值，譬如`3298.34万`需在提取出来后换算为`32983400`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "entitled-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '''<tbody><tr class=\"odd\"><td>1</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000001\">000001</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000001\">上证指数</a></td><td class=\"mywidth2\"><span class=\"green\">3384.98</span></td><td><span class=\"green\">-19.82</span></td><td class=\"mywidth2\"><span class=\"green\">-0.58%</span></td><td>2.55亿</td><td>3507.07亿</td><td>3404.80</td><td><span class=\"green\">3404.03</span></td><td><span class=\"red\">3425.63</span></td><td><span class=\"green\">3374.26</span></td></tr><tr class=\"even\"><td>2</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399001\">399001</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399001\">深证成指</a></td><td class=\"mywidth2\"><span class=\"green\">13772.37</span></td><td><span class=\"green\">-115.06</span></td><td class=\"mywidth2\"><span class=\"green\">-0.83%</span></td><td>4.83亿</td><td>5914.94亿</td><td>13887.43</td><td><span class=\"green\">13871.27</span></td><td><span class=\"red\">13933.42</span></td><td><span class=\"green\">13722.58</span></td></tr><tr class=\"odd\"><td>3</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000300\">000300</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000300\">沪深300</a></td><td class=\"mywidth2\"><span class=\"green\">4817.10</span></td><td><span class=\"green\">-26.79</span></td><td class=\"mywidth2\"><span class=\"green\">-0.55%</span></td><td>1.46亿</td><td>2794.12亿</td><td>4843.89</td><td><span class=\"green\">4841.50</span></td><td><span class=\"red\">4877.01</span></td><td><span class=\"green\">4800.06</span></td></tr><tr class=\"even\"><td>4</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399005\">399005</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399005\">中小板指</a></td><td class=\"mywidth2\"><span class=\"green\">9159.90</span></td><td><span class=\"green\">-108.40</span></td><td class=\"mywidth2\"><span class=\"green\">-1.17%</span></td><td>1.48亿</td><td>1864.07亿</td><td>9268.30</td><td><span class=\"green\">9253.26</span></td><td><span class=\"green\">9264.87</span></td><td><span class=\"green\">9128.93</span></td></tr><tr class=\"odd\"><td>5</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399006\">399006</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399006\">创业板指</a></td><td class=\"mywidth2\"><span class=\"green\">2746.95</span></td><td><span class=\"green\">-24.90</span></td><td class=\"mywidth2\"><span class=\"green\">-0.90%</span></td><td>2.35亿</td><td>2945.09亿</td><td>2771.85</td><td><span class=\"green\">2766.98</span></td><td><span class=\"red\">2789.12</span></td><td><span class=\"green\">2738.13</span></td></tr><tr class=\"even\"><td>6</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000010\">000010</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000010\">上证180</a></td><td class=\"mywidth2\"><span class=\"green\">9926.39</span></td><td><span class=\"green\">-49.35</span></td><td class=\"mywidth2\"><span class=\"green\">-0.49%</span></td><td>8197.01万</td><td>1475.05亿</td><td>9975.74</td><td><span class=\"green\">9975.25</span></td><td><span class=\"red\">10064.05</span></td><td><span class=\"green\">9890.78</span></td></tr><tr class=\"odd\"><td>7</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000016\">000016</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000016\">上证50</a></td><td class=\"mywidth2\"><span class=\"green\">3334.41</span></td><td><span class=\"green\">-12.89</span></td><td class=\"mywidth2\"><span class=\"green\">-0.39%</span></td><td>3125.24万</td><td>675.41亿</td><td>3347.30</td><td><span class=\"red\">3349.26</span></td><td><span class=\"red\">3374.01</span></td><td><span class=\"green\">3322.90</span></td></tr><tr class=\"even\"><td>8</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000009\">000009</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000009\">上证380</a></td><td class=\"mywidth2\"><span class=\"green\">6028.30</span></td><td><span class=\"green\">-47.64</span></td><td class=\"mywidth2\"><span class=\"green\">-0.78%</span></td><td>6107.18万</td><td>772.05亿</td><td>6075.94</td><td><span class=\"green\">6073.58</span></td><td><span class=\"red\">6098.12</span></td><td><span class=\"green\">6007.27</span></td></tr><tr class=\"odd\"><td>9</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000132\">000132</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000132\">上证100</a></td><td class=\"mywidth2\"><span class=\"green\">7161.23</span></td><td><span class=\"green\">-59.43</span></td><td class=\"mywidth2\"><span class=\"green\">-0.82%</span></td><td>1431.32万</td><td>206.40亿</td><td>7220.66</td><td><span class=\"green\">7216.64</span></td><td><span class=\"red\">7248.51</span></td><td><span class=\"green\">7134.41</span></td></tr><tr class=\"even\"><td>10</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000133\">000133</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000133\">上证150</a></td><td class=\"mywidth2\"><span class=\"green\">5118.06</span></td><td><span class=\"green\">-59.18</span></td><td class=\"mywidth2\"><span class=\"green\">-1.14%</span></td><td>1040.19万</td><td>123.99亿</td><td>5177.24</td><td><span class=\"green\">5168.91</span></td><td><span class=\"green\">5171.51</span></td><td><span class=\"green\">5093.68</span></td></tr><tr class=\"odd\"><td>11</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000003\">000003</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000003\">Ｂ股指数</a></td><td class=\"mywidth2\"><span class=\"green\">255.59</span></td><td><span class=\"green\">-0.84</span></td><td class=\"mywidth2\"><span class=\"green\">-0.33%</span></td><td>42.73万</td><td>1.99亿</td><td>256.43</td><td><span class=\"red\">256.77</span></td><td><span class=\"red\">257.81</span></td><td><span class=\"green\">255.26</span></td></tr><tr class=\"even\"><td>12</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000012\">000012</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000012\">国债指数</a></td><td class=\"mywidth2\"><span class=\"red\">182.62</span></td><td><span class=\"red\">0.01</span></td><td class=\"mywidth2\"><span class=\"red\">0.01%</span></td><td>11.84万</td><td>1.11亿</td><td>182.61</td><td><span class=\"red\">182.63</span></td><td><span class=\"red\">182.63</span></td><td><span class=\"green\">182.60</span></td></tr><tr class=\"odd\"><td>13</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000013\">000013</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000013\">企债指数</a></td><td class=\"mywidth2\"><span class=\"green\">247.18</span></td><td><span class=\"green\">-0.01</span></td><td class=\"mywidth2\"><span class=\"fair\">0.00%</span></td><td>116.01万</td><td>10.03亿</td><td>247.19</td><td><span class=\"red\">247.22</span></td><td><span class=\"red\">247.23</span></td><td><span class=\"green\">247.18</span></td></tr><tr class=\"even\"><td>14</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000011\">000011</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000011\">基金指数</a></td><td class=\"mywidth2\"><span class=\"green\">7270.86</span></td><td><span class=\"green\">-30.69</span></td><td class=\"mywidth2\"><span class=\"green\">-0.42%</span></td><td>9186.44万</td><td>384.98亿</td><td>7301.55</td><td><span class=\"green\">7295.68</span></td><td><span class=\"red\">7323.65</span></td><td><span class=\"green\">7255.62</span></td></tr><tr class=\"odd\"><td>15</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399002\">399002</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399002\">深成指R</a></td><td class=\"mywidth2\"><span class=\"green\">17078.61</span></td><td><span class=\"green\">-142.67</span></td><td class=\"mywidth2\"><span class=\"green\">-0.83%</span></td><td>9975.40万</td><td>1105.11亿</td><td>17221.28</td><td><span class=\"green\">17201.25</span></td><td><span class=\"red\">17278.32</span></td><td><span class=\"green\">17016.86</span></td></tr><tr class=\"even\"><td>16</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399003\">399003</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399003\">成份Ｂ指</a></td><td class=\"mywidth2\"><span class=\"green\">5929.36</span></td><td><span class=\"green\">-18.39</span></td><td class=\"mywidth2\"><span class=\"green\">-0.31%</span></td><td>14.65万</td><td>6716.08万</td><td>5947.75</td><td><span class=\"green\">5946.82</span></td><td><span class=\"red\">6012.30</span></td><td><span class=\"green\">5929.36</span></td></tr><tr class=\"odd\"><td>17</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399106\">399106</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399106\">深证综指</a></td><td class=\"mywidth2\"><span class=\"green\">2301.81</span></td><td><span class=\"green\">-19.59</span></td><td class=\"mywidth2\"><span class=\"green\">-0.84%</span></td><td>4.83亿</td><td>5914.94亿</td><td>2321.40</td><td><span class=\"green\">2317.98</span></td><td><span class=\"red\">2327.14</span></td><td><span class=\"green\">2293.11</span></td></tr><tr class=\"even\"><td>18</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399004\">399004</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399004\">深证100R</a></td><td class=\"mywidth2\"><span class=\"green\">8141.33</span></td><td><span class=\"green\">-61.97</span></td><td class=\"mywidth2\"><span class=\"green\">-0.76%</span></td><td>5181.20万</td><td>1303.54亿</td><td>8203.30</td><td><span class=\"green\">8190.79</span></td><td><span class=\"red\">8243.57</span></td><td><span class=\"green\">8109.45</span></td></tr><tr class=\"odd\"><td>19</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399007\">399007</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399007\">深证300</a></td><td class=\"mywidth2\"><span class=\"green\">5930.20</span></td><td><span class=\"green\">-46.57</span></td><td class=\"mywidth2\"><span class=\"green\">-0.78%</span></td><td>1.12亿</td><td>2167.71亿</td><td>5976.77</td><td><span class=\"green\">5969.03</span></td><td><span class=\"red\">6001.90</span></td><td><span class=\"green\">5908.51</span></td></tr><tr class=\"even\"><td>20</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399008\">399008</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399008\">中小300</a></td><td class=\"mywidth2\"><span class=\"green\">1714.90</span></td><td><span class=\"green\">-20.34</span></td><td class=\"mywidth2\"><span class=\"green\">-1.17%</span></td><td>7645.62万</td><td>1232.47亿</td><td>1735.24</td><td><span class=\"green\">1732.85</span></td><td><span class=\"green\">1734.09</span></td><td><span class=\"green\">1709.41</span></td></tr><tr class=\"odd\"><td>21</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399293\">399293</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399293\">创业大盘</a></td><td class=\"mywidth2\"><span class=\"green\">5165.43</span></td><td><span class=\"green\">-45.37</span></td><td class=\"mywidth2\"><span class=\"green\">-0.87%</span></td><td>1574.70万</td><td>566.49亿</td><td>5210.80</td><td><span class=\"green\">5200.38</span></td><td><span class=\"red\">5253.12</span></td><td><span class=\"green\">5149.50</span></td></tr><tr class=\"even\"><td>22</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399100\">399100</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399100\">新 指 数</a></td><td class=\"mywidth2\"><span class=\"green\">10529.25</span></td><td><span class=\"green\">-90.53</span></td><td class=\"mywidth2\"><span class=\"green\">-0.85%</span></td><td>4.69亿</td><td>5788.45亿</td><td>10619.78</td><td><span class=\"green\">10603.97</span></td><td><span class=\"red\">10645.74</span></td><td><span class=\"green\">10489.83</span></td></tr><tr class=\"odd\"><td>23</td><td><a href=\"//quote.eastmoney.com/unify/r/0.399550\">399550</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/0.399550\">央视50</a></td><td class=\"mywidth2\"><span class=\"green\">8381.39</span></td><td><span class=\"green\">-21.93</span></td><td class=\"mywidth2\"><span class=\"green\">-0.26%</span></td><td>1929.08万</td><td>610.48亿</td><td>8403.32</td><td><span class=\"red\">8408.16</span></td><td><span class=\"red\">8480.02</span></td><td><span class=\"green\">8356.83</span></td></tr><tr class=\"even\"><td>24</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000905\">000905</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000905\">中证500</a></td><td class=\"mywidth2\"><span class=\"green\">6662.25</span></td><td><span class=\"green\">-55.31</span></td><td class=\"mywidth2\"><span class=\"green\">-0.82%</span></td><td>1.42亿</td><td>1515.92亿</td><td>6717.56</td><td><span class=\"green\">6715.10</span></td><td><span class=\"red\">6732.67</span></td><td><span class=\"green\">6638.45</span></td></tr><tr class=\"odd\"><td>25</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000903\">000903</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000903\">中证100</a></td><td class=\"mywidth2\"><span class=\"green\">4822.56</span></td><td><span class=\"green\">-19.79</span></td><td class=\"mywidth2\"><span class=\"green\">-0.41%</span></td><td>7130.03万</td><td>1375.80亿</td><td>4842.35</td><td><span class=\"red\">4842.58</span></td><td><span class=\"red\">4886.04</span></td><td><span class=\"green\">4806.00</span></td></tr><tr class=\"even\"><td>26</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000906\">000906</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000906\">中证800</a></td><td class=\"mywidth2\"><span class=\"green\">5121.67</span></td><td><span class=\"green\">-31.94</span></td><td class=\"mywidth2\"><span class=\"green\">-0.62%</span></td><td>2.88亿</td><td>4310.04亿</td><td>5153.61</td><td><span class=\"green\">5151.23</span></td><td><span class=\"red\">5182.94</span></td><td><span class=\"green\">5103.51</span></td></tr><tr class=\"odd\"><td>27</td><td><a href=\"//quote.eastmoney.com/unify/r/1.000688\">000688</a></td><td class=\"mywidth\"><a href=\"//quote.eastmoney.com/unify/r/1.000688\">科创50</a></td><td class=\"mywidth2\"><span class=\"green\">1402.14</span></td><td><span class=\"green\">-20.81</span></td><td class=\"mywidth2\"><span class=\"green\">-1.46%</span></td><td>530.49万</td><td>310.18亿</td><td>1422.95</td><td><span class=\"green\">1422.42</span></td><td><span class=\"red\">1423.89</span></td><td><span class=\"green\">1396.11</span></td></tr></tbody>'''\n",
    "result =[] \n",
    "for s in re.findall('>([0-9.]+[万|亿])<',target):\n",
    "#     print(s[:-1])\n",
    "    if s.endswith == '万':\n",
    "        _ = round(float(s[:-1])*1e4)\n",
    "    else:\n",
    "        _ = round(float(s[:-1])*1e8)\n",
    "    result.append(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-atlantic",
   "metadata": {},
   "source": [
    "### Day10 正则中常见的`\\`开头特殊序列的用法\n",
    "- 除了可以对正则表达式中的元字符进行转义\n",
    "- `\\`还可以衔接一些特殊的字母，从而起到很多特殊作用\n",
    "    - `\\s` 和`\\S`\n",
    "         - `\\s`用于概括包括`\\n`(换行)，`\\t`(制表符)等在内的**unicode空白符**，即字符串在被打印后看起来是空白的区域\n",
    "         - `\\S`的意义则相当于对`\\s`取反，即匹配所有非**unicode空白字符**\n",
    "    - `\\d`与`\\D`\n",
    "         - `\\d`用于表示任意10进制数字，等价于`[0-9]`\n",
    "         - `\\D`与`\\d`意义相反，代表除了数字外的所有其他字符，等价于`[^0-9]`\n",
    "    - `\\w`和`\\W`\n",
    "         - `\\w`代表着常规的组成词语(**各种语言的**`单词`，`汉字`等)的**unicode字符**，默认状态下也包括了`数字`与`下划线`，类似于Python的`变量命名规则`中对变量名合法性的定义\n",
    "         - `\\W`则取`\\w`相反的意义\n",
    "         - **补充：**对汉字的匹配\n",
    "             - 虽然前面我们发现了`\\w`可以匹配语言中的词汇内容，但是不分国籍全部匹配到了\n",
    "             - 如果我们真正需要的是原始字符串中的**中文汉字**内容，比如<ins>制作词云图之前的数据清洗过程</ins>,我们可以使用到常见汉字在**unicode编码**中的范围`\\u4e00`到`\\u9fa5`,这囊括了常见的20902个汉字\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "packed-departure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\tb\tc\td\n",
      "e\tf\tg\th\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['\\t', '\\t', '\\t', '\\n', '\\t', '\\t', '\\t'],\n",
       " ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\\s和\\S\n",
    "'''\n",
    "这类字符串的特点就是打印出来之后只能看到或长或短的空白或者换行，\n",
    "可以使用\\s来匹配到这类字符\n",
    "'''\n",
    "s = 'a\\tb\\tc\\td\\ne\\tf\\tg\\th'\n",
    "print(s)\n",
    "re.findall('\\s+',s),re.findall('\\S+',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "innocent-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['21312', '21312', '321312'], ['hghgf', 'ghhhg'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\\d和\\D\n",
    "s = '21312hghgf21312ghhhg321312'\n",
    "re.findall('\\d+',s),re.findall('\\D+',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "american-oxide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['今天',\n",
       "  '是1个好日子_',\n",
       "  'today',\n",
       "  'is',\n",
       "  'a',\n",
       "  'good',\n",
       "  'day',\n",
       "  '今日はいい日だ',\n",
       "  '오늘은',\n",
       "  '좋은',\n",
       "  '날이다',\n",
       "  'Aujourd',\n",
       "  'hui',\n",
       "  'est',\n",
       "  'un',\n",
       "  'bon',\n",
       "  'jour',\n",
       "  'Ein',\n",
       "  'guter',\n",
       "  'tag',\n",
       "  'Хороший',\n",
       "  'день'],\n",
       " ['，',\n",
       "  '，',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  '，',\n",
       "  '，',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  '，',\n",
       "  '’',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  '，',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  '，',\n",
       "  ' ',\n",
       "  '.'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\\w和\\W\n",
    "s = '今天，是1个好日子_，today is a good day，今日はいい日だ，오늘은 좋은 날이다，Aujourd’hui est un bon jour，Ein guter tag，Хороший день.'\n",
    "\n",
    "re.findall('\\w+',s),re.findall('\\W+',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "brave-watson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['观察者网讯',\n",
       " '美国政府对中国科技企业',\n",
       " '卡脖子',\n",
       " '如今盯上了中芯国际',\n",
       " '路透社',\n",
       " '月',\n",
       " '日援引消息人士称',\n",
       " '特朗普政府正考虑是否将中国最大的芯片制造商中芯国际',\n",
       " '加入',\n",
       " '实体清单']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#常见汉字\n",
    "s = '观察者网讯）美国政府对中国科技企业“卡脖子”，如今盯上了中芯国际。路透社9月4日援引消息人士称，特朗普政府正考虑是否将中国最大的芯片制造商中芯国际（SMIC）加入“实体清单”。'\n",
    "re.findall('[\\u4e00-\\u9fa5]+',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-capitol",
   "metadata": {},
   "source": [
    "### Day10 练习\n",
    "- 从目标字符串中匹配所有5字及以上的且不以年和天结尾的成语："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "artificial-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一物降一物',\n",
       " '富贵不能淫',\n",
       " '水至清则无鱼',\n",
       " '欲速则不达',\n",
       " '巧妇难为无米之炊',\n",
       " '君子之交淡如水',\n",
       " '鲤鱼跳龙门',\n",
       " '十八般武艺',\n",
       " '二一添作五',\n",
       " '饱暖思淫欲',\n",
       " '五十步笑百步']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '一物降一物、过眼云烟、勾心斗角、富贵不能淫、水至清则无鱼、九牛一毛、Absence makes the heart grow fonder.欲速则不达、巧妇难为无米之炊、民以食为天、君子之交淡如水、枯木逢春、鲤鱼跳龙门、志同道合、No cross, no crown.十八般武艺、二一添作五、East or west, home is best.饱暖思淫欲、瑞雪兆丰年、五十步笑百步'\n",
    "tmp = re.findall('[\\u4e00-\\u9fa5]{5,}',target)\n",
    "# print(tmp)\n",
    "[s for s in tmp if re.findall('\\w[^天|年]$',s) != []]\n",
    "[s for s in tmp if re.findall('.*?[^天年]$',s) != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-canada",
   "metadata": {},
   "source": [
    "### Day11 正则中的“非获取匹配”\n",
    "- 直接使用`{7,10}`的正则方式会把某些长度超过上限的单词直接截断。\n",
    "- `非获取匹配`是指在匹配过程中匹配的模式\n",
    "    - 在经过`非获取匹配`类的表达式匹配之后不会被消耗\n",
    "    - `正向肯定预查`：**`(?=模式)修饰符`**\n",
    "        - 即用来表示目标字符串之后的辅助模式\n",
    "        - 参考下面的使用范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "tired-joint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['specific', 'textual', 'patterns', 'distinct', 'notation']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "请你提取出所有长度在7到10之间的单词\n",
    "\n",
    "方法2虽然也能实现，但是很多符合要求的词会被遗漏\n",
    "这是因为`\\W+`在匹配单词边界的过程中会被消耗\n",
    "\n",
    "比如`expression`有10个单词，且经过处理后两边都是空格满足正则的要求，\n",
    "但是其右侧的空格在完成对`expression`的匹配后，\n",
    "便被消耗掉了，导致正则继续往右尝试匹配`specific`时，由于`specific`左侧空格已经被消耗，\n",
    "所以`specific`会被遗漏\n",
    "'''\n",
    "s = 'expression specific standard textual representing patterns matching text distinct mathematical notation described'\n",
    "#方法1\n",
    "re.findall('[a-z]{7,10}',s)\n",
    "\n",
    "#方法2\n",
    "re.findall('\\W+([a-z]{7,10})\\W+',''+s+'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "signed-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expression',\n",
       " 'specific',\n",
       " 'standard',\n",
       " 'textual',\n",
       " 'patterns',\n",
       " 'matching',\n",
       " 'distinct',\n",
       " 'notation',\n",
       " 'described']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#非获取匹配\n",
    "'''\n",
    "下面的`(?=模式)修饰符`的用法，称为`正向肯定预查`\n",
    "\n",
    "下面的正则可翻译为：\n",
    "**匹配两边是非字母的7到10字单词，\n",
    "且右侧辅助定位的非单词部分在匹配之后仍然可以接着被之后的匹配过程使用到**\n",
    "'''\n",
    "re.findall('\\W+([a-z]{7,10})(?=\\W)+',' '+s+' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-stretch",
   "metadata": {},
   "source": [
    "### Day11 练习\n",
    "- 从下面的字符串中提取出所有的手机号码（1开头的连续11位数字）及座机号码（若干数字+`-`+若干数字）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "permanent-seeker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13988887777',\n",
       " '18988887777',\n",
       " '010-3232112',\n",
       " '023-8988988',\n",
       " '18900990099',\n",
       " '0554-9888889']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '13988887777 18988887777 010-3232112 023-8988988 18900990099 dsddsa 21321 32232321232 fsfdf34134 1413431 0554-9888889'\n",
    "\n",
    "re.findall('\\W+([1]+[0-9]{10}|[0-9]+-[0-9]+)(?=\\W)+',' '+target+' ')\n",
    "#别人写的\n",
    "re.findall('\\W+([01]+[0-9-]{10,})(?=\\W)+',' '+target+' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-avatar",
   "metadata": {},
   "source": [
    "### Day12\n",
    "- 常见的4种不同功能的`非获取匹配`语法\n",
    "    - **`?=`**:正向肯定预查：按照`模式1(?=模式2)`的格式，其意义为以`非获取匹配`的方式对后面仅仅衔接`模式2`的`模式1`进行匹配\n",
    "    - **`?!`**:正向否定预查：与正向肯定预查功能相反，按照`模式1(?!模式2)`的格式，其意义为以`非获取匹配`的方式对后面不衔接`模式2`的`模式1`进行匹配\n",
    "    - **`?<=`**:反向肯定预查：按照`(?<=模式1)模式2`的格式，其意义为以'非获取匹配'的方式对前面为`模式1`的`模式2`进行匹配\n",
    "    - **`?<!`**:反向否定预查：按照`(?<!模式1)模式2`的格式，其意义为以`非获取匹配`的方式对前面不为`模式1`的`模式2`进行匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "filled-holly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''正向肯定预查'''\n",
    "# 匹配所有 两个大写字母一个数字_ 中的“两个大写字母”\n",
    "s = '_AA2_AA2_AA2_AA2_BB3|'\n",
    "\n",
    "#想当然的匹配方法，由于前面的匹配过程中'_'被消耗，导致之后的匹配失败\n",
    "re.findall('_([A-Z]{2})\\d{1}_',s)\n",
    "\n",
    "#正向肯定预查\n",
    "re.findall('_([A-Z]{2})(?=\\d{1}_)',s)\n",
    "# re.findall('_([A-Z]{2})\\d{1}',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "massive-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''正向否定预查'''\n",
    "# 匹配所有 两个大写字母一个数字且之后不衔接| 中的“两个大写字母”\n",
    "s = '_AA2_AA2_AA2_AA2_BB3|'\n",
    "\n",
    "#配合正向否定预查\n",
    "re.findall('_([A-Z]{2})(?!\\d{1}\\|)',s)\n",
    "re.findall('_([A-Z]{2})\\d{1}(?!\\|)',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "objective-sodium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''反向肯定预查'''\n",
    "# 匹配所有 _两个大写字母一个数字_ 中的“两个大写字母”\n",
    "s = '_AA2_AA2_AA2_AA2_BB3|'\n",
    "\n",
    "# re.findall('(?<=_)([A-Z]{2})\\d{1}(?!\\|)',s)\n",
    "re.findall('(?<=_)([A-Z]{2})\\d{1}(?=_)',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "alternate-theater",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''反向否定预查'''\n",
    "# 匹配所有 非_两个大写字母一个数字 中的“两个大写字母”\n",
    "s = '|AA2|AA2|AA2|AA2_BB3_'\n",
    "\n",
    "re.findall('(?<!_)([A-Z]{2})\\d{1}',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-hypothetical",
   "metadata": {},
   "source": [
    "### Day12 练习\n",
    "- 观察下面的字符串，然后提取出符合`XXX(v或a)` 的 `XX(n) XX(n) ... XX(n`的内容，即从动词或形容词开始，经过衔接`的`以及之后连续的名词内容，且开头的动词或形容词前的代号必须为11，譬如下面的target中`严重(a) 的 军事(n) 挑衅(n) 行为(n)`就满足要求，而`交涉(v) 的 中国边防部队(n) 巡逻(n) 人员(n)`不满足要求（请你必须使用到今天所教的“非获取匹配”中的至少一种方法）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "naughty-knife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['严重(a) 的 军事(n) 挑衅(n) 行为(n)']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '''00交涉(v) 的 中国边防部队(n) 巡逻(n) 人员(n) 鸣枪(v) 威胁(v) 11严重(a) 的 军事(n) 挑衅(n) 行为(n) 令人发指(i)'''\n",
    "\n",
    "re.findall('(?<=11)(.+)(?=\\s.+\\(i\\))',target)\n",
    "#别人写的\n",
    "re.findall('(?<=11)(.*n\\W)',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-influence",
   "metadata": {},
   "source": [
    "### Day13 `findall` & `finditer`\n",
    "- `finditer`与`findall`功能相同，但更适用于大型数据\n",
    "- `findall` 3个参数\n",
    "    - `pattern`:代表传入的正则表达式\n",
    "    - `string`:代表原始字符串\n",
    "    - `flags`:它的传入值是`re`中内置的一系列特殊对象\n",
    "        - `re.IGNORECASE`:可以简写成`re.I`，作用是使得我们的正则忽略字母的大小写区别\n",
    "        - `re.MULTILINE`:可以简写成`re.M`，作用体现在原始字符串中存在换位符时，将`^`的作用由定位字符串开始变为定位每一行的开始，将`$`的作用由定位字符串变为定位每一行的结束\n",
    "        - `re.DOTALL`:可以简写为`re.S`,在前面的学习中我们知道了`.`可以代表任何**非换行符**的单个字符，而传入`flags=re.S`后，`.`就可以真正意义上代表任何单个字符了\n",
    "            - 这在网页匹配中经常用到。因为`HTML节点经常会有换行`。\n",
    "        - `re.L`:做本地化识别**（locale-aware）**匹配\n",
    "|修饰符|描述|\n",
    "|-|-|\n",
    "|`re.I`|使匹配对大小写不敏感|\n",
    "|`re.L`|做本地化识别(locale-aware)匹配|\n",
    "|`re.M`|多行匹配，影响`^`和`$`|\n",
    "|`re.S`|使匹配包括换行在内的所有字符|\n",
    "|`re.U`|根据Unicode字符集解析字符。这个标志影响`\\w`,`\\W`,`\\b`,`\\B`|\n",
    "|`re.X`|该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解|\n",
    "- `finditer`:返回结果具有独特的机制\n",
    "    - 具体可参考下述example\n",
    "    - 因为是迭代器，所以只有在对其进行遍历时才会取到对应位置的元素，非常节省内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "sensitive-boating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAABBBcccddd']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''re.IGNORECASE'''\n",
    "\n",
    "s = 'AAABBBcccddd'\n",
    "\n",
    "#`re.I`使用前\n",
    "re.findall('[a-z]+',s)\n",
    "\n",
    "#`re.I`使用后\n",
    "re.findall('[a-z]+',s,flags = re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "apart-shock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcd', 'efgh', 'ijkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''re.MULTILINE'''\n",
    "\n",
    "s = '''abcd\n",
    "efgh\n",
    "ijkl'''\n",
    "\n",
    "#re.M使用前\n",
    "re.findall('^[a-z]{4,}',s)\n",
    "\n",
    "#re.M使用后\n",
    "re.findall('^[a-z]{4,}',s,flags =re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "smooth-lobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['第一行\\n第二行\\n第三行']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''re.DOTALL'''\n",
    "\n",
    "s = '''第一行\n",
    "第二行\n",
    "第三行'''\n",
    "\n",
    "#re.S使用前\n",
    "re.findall('.+',s)\n",
    "\n",
    "#re.S使用后\n",
    "re.findall('.+',s,flags=re.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "greek-national",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, callable_iterator)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''finditer'''\n",
    "\n",
    "s = 'abc'*100000\n",
    "result1 = re.findall('[a-z]{3}', s)\n",
    "result2 = re.finditer('[a-z]{3}',s)\n",
    "type(result1),type(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "brutal-alpha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for _ in result2:\n",
    "    tmp.append(_)\n",
    "tmp[:10]\n",
    "\n",
    "tmp[0].group()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-google",
   "metadata": {},
   "source": [
    "### Day13 练习\n",
    "- 提取出下面字符串中每一个单独的短句\n",
    "    - （譬如`公然放弃在主权争议上不持立场的\n",
    "承诺，直接介入本地区领土和海洋争端。仅上半年，`中的单独短句为`公然放弃在主权争议上不持立场的\n",
    "承诺`，`直接介入本地区领土和海洋争端`以及`仅上半年`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "marine-ribbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['今年的最新动向',\n",
       "  '就是美国出于自身政治需要',\n",
       "  '公然放弃在主权争议上不持立场的承诺',\n",
       "  '直接介入本地区领土和海洋争端',\n",
       "  '仅上半年',\n",
       "  '美国就派出近3000架次军机',\n",
       "  '60余艘次军舰',\n",
       "  '包括多批次轰炸机和双航母编队',\n",
       "  '不断在南海炫耀武力',\n",
       "  '强化军事部署',\n",
       "  '甚至在与其毫不相干的争议海域横冲直撞',\n",
       "  '肆意推高地区冲突风险',\n",
       "  '正在成为南海军事化的最大推手',\n",
       "  '美国还对“南海行为准则”磋商指手划脚',\n",
       "  '干扰中国和东盟国家协商解决争议的努力',\n",
       "  '挑动地区国家对立对抗',\n",
       "  '美方的所做所为',\n",
       "  '就是要搞乱南海',\n",
       "  '搞乱地区',\n",
       "  '为推进其“印太战略”制造借口']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '''今年的最新动向，就是美国出于自身政治需要，公然放弃在主权争议上不持立场的\n",
    "承诺，直接介入本地区领土和海洋争端。仅上半年，美国就派出近3000架次军机、60余艘次军舰，\n",
    "包括多批次轰炸机和双航母编队，不断在南海炫耀武力，强化军事部署，甚至在与其毫不相干的争\n",
    "议海域横冲直撞，肆意推高地区冲突风险，正在成为南海军事化的最大推手。美国还对“南海行为\n",
    "准则”磋商指手划脚，干扰中国和东盟国家协商解决争议的努力，挑动地区国家对立对抗，美方的\n",
    "所做所为，就是要搞乱南海，搞乱地区，为推进其“印太战略”制造借口。'''\n",
    "\n",
    "'''\n",
    "思路：先用re.S把\\n换行符识别出来后替换掉再进行匹配\n",
    "“”要放入`[]`里后才会被一起被匹配\n",
    "'''\n",
    "\n",
    "[re.findall('([\\w+“”]+)[，。、]',s.replace('\\n','')) for s in re.findall('(\\w+.+)',target,re.S)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-sellers",
   "metadata": {},
   "source": [
    "### Day14 `re`中的`split`\n",
    "- 在文本分句等场景中很常用\n",
    "- 将传入的正则模式作为分割依据，从而对目标字符串进行分割\n",
    "- 如果用`()`包裹分割模式，`分隔符`也会被单独作为分割出的字符片段被返回\n",
    "- `split`还有一个独特的参数:`maxsplit`，默认为0时不起作用。\n",
    "    - 当设置为大于等于1的整数时，用于`限定最大分割次数`,当超过这个次数后，剩余未被分割的字符会作为返回结果的最后一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "korean-cinema",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interpreted',\n",
       " 'high-level',\n",
       " 'and',\n",
       " 'general-purpose',\n",
       " 'programming',\n",
       " 'language',\n",
       " '']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 利用分割字符串的方式提取所有单词\n",
    "'''\n",
    "可以看到，对下面的例子，\n",
    "当我们按照除了大小写字母和连字符号之外的其他任意单个及以上字符\n",
    "作为分割依据时，就可以把所有单词提取出来\n",
    "'''\n",
    "s = 'Python is an interpreted, high-level and general-purpose programming language.'\n",
    "re.split('[^\\w-]+',s)\n",
    "re.split('[^a-zA-Z-]+',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "frequent-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " ' ',\n",
       " 'is',\n",
       " ' ',\n",
       " 'an',\n",
       " ' ',\n",
       " 'interpreted',\n",
       " ', ',\n",
       " 'high-level',\n",
       " ' ',\n",
       " 'and',\n",
       " ' ',\n",
       " 'general-purpose',\n",
       " ' ',\n",
       " 'programming',\n",
       " ' ',\n",
       " 'language',\n",
       " '.',\n",
       " '']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''用`()`包裹分割模式'''\n",
    "re.split('([^a-zA-Z-]+)',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "american-liberia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interpreted, high-level and general-purpose programming language.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''设定maxsplit大于等于1'''\n",
    "re.split('[^a-zA-Z-]',s,maxsplit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-baseball",
   "metadata": {},
   "source": [
    "### Day14 练习\n",
    "- 提取出下面字符串中每一个单独的短句\n",
    "    - （譬如公然放弃在主权争议上不持立场的\n",
    "    承诺，直接介入本地区领土和海洋争端。仅上半年，中的单独短句为公然放弃在主权争议上不持立场的\n",
    "    承诺，直接介入本地区领土和海洋争端以及仅上半年）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "romance-christmas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['今年的最新动向',\n",
       " '就是美国出于自身政治需要',\n",
       " '公然放弃在主权争议上不持立场的承诺',\n",
       " '直接介入本地区领土和海洋争端',\n",
       " '仅上半年',\n",
       " '美国就派出近3000架次军机',\n",
       " '60余艘次军舰',\n",
       " '包括多批次轰炸机和双航母编队',\n",
       " '不断在南海炫耀武力',\n",
       " '强化军事部署',\n",
       " '甚至在与其毫不相干的争议海域横冲直撞',\n",
       " '肆意推高地区冲突风险',\n",
       " '正在成为南海军事化的最大推手',\n",
       " '美国还对“南海行为准则”磋商指手划脚',\n",
       " '干扰中国和东盟国家协商解决争议的努力',\n",
       " '挑动地区国家对立对抗',\n",
       " '美方的所做所为',\n",
       " '就是要搞乱南海',\n",
       " '搞乱地区',\n",
       " '为推进其“印太战略”制造借口']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '''今年的最新动向，就是美国出于自身政治需要，公然放弃在主权争议上不持立场的\n",
    "承诺，直接介入本地区领土和海洋争端。仅上半年，美国就派出近3000架次军机、60余艘次军舰，\n",
    "包括多批次轰炸机和双航母编队，不断在南海炫耀武力，强化军事部署，甚至在与其毫不相干的争\n",
    "议海域横冲直撞，肆意推高地区冲突风险，正在成为南海军事化的最大推手。美国还对“南海行为\n",
    "准则”磋商指手划脚，干扰中国和东盟国家协商解决争议的努力，挑动地区国家对立对抗，美方的\n",
    "所做所为，就是要搞乱南海，搞乱地区，为推进其“印太战略”制造借口。'''\n",
    "\n",
    "[i.replace('\\n','') for i in re.split('[^\\w\\n“”]',target) if i != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-habitat",
   "metadata": {},
   "source": [
    "### Day15 `re`中的`sub`\n",
    "- `sub`代表单词substitute，即替换\n",
    "- 通过`re.sub`可以用正则表达式来概括字符串中我们想要替换的部分\n",
    "    - 第一个参数`pattern`：代表将要替换的字符串片段的正则模式\n",
    "    - 第二个参数`repl`：代表替换之后新的字符串\n",
    "    - 第三个参数`string`：代表原始字符串\n",
    "    - 第四个参数`count`：代表最大替换次数，默认为**0**的时候代表不限制\n",
    "    - 最后一个参数`flags`：参考`Day13`的说明\n",
    "- 通过`sub`可以实现搜索并进行字符替换，这在将原本脏乱的数值`清洗为纯数值`时非常实用\n",
    "    - 对于网页提取，可以先用sub方法将a节点去掉，只留下文本，再利用`findall`提取即可\n",
    "- `re.subn`:功能与`re.sub`相似，不同的是它在对原始字符串进行替换的同时，会一并返回`总共发生替换的次数`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "chinese-jungle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23.12'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将所有非数字和小数点的部分替换为空字符\n",
    "s = '“23.12%”'\n",
    "\n",
    "# re.sub('[^0-9.]','',s)\n",
    "re.sub('[^\\d\\.]+','',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "passing-dublin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('汪文斌指出，美国个别政客一方面鼓吹要实现公平对等，构建所谓的“清洁网络”，另一方面却又在拿不出任何证据的情况下，泛化国家安全概念，滥用国家力量，对某一领域取得领先优势的非美国企业进行无理打压和百般胁迫，这充分暴露了美方少数政客强取豪夺的真实用意和经济霸凌的丑陋面目。',\n",
       " 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将所有换行符替换为空，并返回总共找到的换行次数\n",
    "s = '''汪文斌指出，美国个别政客一方面鼓吹要实现公平对等，构建所谓的“清洁网络”，\n",
    "另一方面却又在拿不出任何证据的情况下，泛化国家安全概念，滥用国家力量，对某一领域\n",
    "取得领先优势的非美国企业进行无理打压和百般胁迫，这充分暴露了美方少数政客强取豪夺\n",
    "的真实用意和经济霸凌的丑陋面目。'''\n",
    "\n",
    "re.subn('\\n+','',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "other-german",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aKyroiRixLg'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#去掉一串文本中的所有数字\n",
    "content = '54aK54yr5oiR54ix5L2g'\n",
    "re.sub('\\d+','',content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-angel",
   "metadata": {},
   "source": [
    "### Day15 练习\n",
    "- 请你利用`sub`，将下列列表中所有的元素转化为可执行运算的数值，并计算出他们的**最大值**，其中K代表千，M代表百万："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "silver-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['32132.321', '12.89%', '20K', '120M', '200,000,000']\n",
    "result = []\n",
    "for i in target:\n",
    "    if 'K' in i:\n",
    "        i = re.sub('K','000',i)\n",
    "    elif 'M' in i:\n",
    "        i = re.sub('M','000000',i)\n",
    "    else:\n",
    "        i = re.sub(',','',i)\n",
    "    result.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-reservoir",
   "metadata": {},
   "source": [
    "### Day16 正则中的分组\n",
    "- `分组`\n",
    "    - 体现在我们书写正则表达式时使用到两对及以上的`()`\n",
    "    - 就像下面的例子一样，我们感兴趣的是字典中的键值对，而*键*与*值*在匹配时是一套模式下的不同位置对应字符片段。因此像下面的例子一样结果是成对的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "postal-netscape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lng', '106.323233'), ('lat', '29.989878'), ('altitude', '-9.9')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''在应用正则表达式的过程中，我们经常会遇到下面这样的问题'''\n",
    "s = '''{\"lng\": 106.323233, \n",
    "        \"lat\": 29.989878,\n",
    "        \"altitude\": -9.9}'''\n",
    "# 找出所有的键值对\n",
    "re.findall('\"(.*?)\": (.*?)[,\\}]',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "northern-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'abc', 'abc', 'abc']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 匹配连续出现的abc\n",
    "s = 'abcabc abcabcabc abc abcabcabcabc'\n",
    "\n",
    "re.findall('(abc)+',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-fellowship",
   "metadata": {},
   "source": [
    "- 上诉未得到理想结果是因为这里的`()`划定出的分组匹配模式依旧是内部包裹的`abc`\n",
    "- 后面紧跟的`+`虽然配合`(abc)`的确表示我们想要的模式，但因为没有继续被`()`包裹，所以只是匹配到且消耗掉，并不会作为返回结果返回\n",
    "- 因为需要继续嵌套`()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "opening-humor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abcabc', 'abc'),\n",
       " ('abcabcabc', 'abc'),\n",
       " ('abc', 'abc'),\n",
       " ('abcabcabcabc', 'abc')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('((abc)+)',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-reward",
   "metadata": {},
   "source": [
    "- 我们会发现返回的结果列表中每个元素都是`2元组`\n",
    "- 其中每个2元组第一个元素是我们想要的内容，而第二个元素则跟之前遇到的情况一致\n",
    "- 这就是正则的分组在搞鬼\n",
    "\n",
    "\n",
    "- 对于像上述例子所示存在嵌套分组的情况时，`从左往右数`所有成对`小括号`中的`左括号`，依次就代表`第1组`，`第2组`....`第n组`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "graduate-wright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abcdef', 'abcde', 'abcd', 'abc', 'ab', 'a'),\n",
       " ('abcdef', 'abcde', 'abcd', 'abc', 'ab', 'a'),\n",
       " ('abcdef', 'abcde', 'abcd', 'abc', 'ab', 'a')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'abcdef abcdef abcdef'\n",
    "re.findall('((((((a)b)c)d)e)f)',s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-referral",
   "metadata": {},
   "source": [
    "### Day16 练习\n",
    "- 从下面的字符串中利用分组的知识提取出每个格式如(市全称, 市简称, 区全程, 区简称)，譬如('重庆市', '重庆', '渝中区', '渝中'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "suited-laugh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('重庆市', '重庆', '渝中区', '渝中'),\n",
       " ('北京市', '北京', '西城区', '西城'),\n",
       " ('成都市', '成都', '武侯区', '武侯')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = '重庆市渝中区 北京市西城区 成都市武侯区'\n",
    "\n",
    "# re.findall('((.+?)[市区])',target)\n",
    "re.findall('((.{2})市)((.{2})区)',target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-destruction",
   "metadata": {},
   "source": [
    "### Day17 正则表达式在pandas中的应用\n",
    "- **str.count**\n",
    "    \n",
    "    在针对字符型`Series`以及`DataFrame`中的字符型列时，我们可以使用`str.count`来捕获每个元素中待搜索模式出现的次数\n",
    "    \n",
    "    \n",
    "- **str.contains**\n",
    "\n",
    "    利用`str.contains`，我们可以分别检查`Series`中是否存在某种模式\n",
    "    \n",
    "    \n",
    "- **str.replace**\n",
    "\n",
    "    利用`str.replace`，可以灵活地对原数据中异常字符进行发现并替换操作\n",
    "    这在数据清洗时非常实用\n",
    "    \n",
    "    \n",
    "- **str.findall**\n",
    "\n",
    "    `str.findall`类似`re`中`findall`地功能，可以帮助我们从原始元素中提取所有满足匹配模式的元素\n",
    "    \n",
    "    \n",
    "- **str.split**\n",
    "\n",
    "    利用`str.split`我们可以对每个元素快捷地进行模式分割\n",
    "    \n",
    "    设置`expand = True`，每个单独分割出的元素会形成单独的列（总列数以最大分割出地分段字符数量为准）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "intended-zambia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35\n",
       "1    15\n",
       "2    32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#str.count\n",
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(['国务院总理李克强9月15日晚在人民大会堂出席世界经济论坛全球企业家特别对话会，',\n",
    "               '发表致辞并同企业家代表互动交流。',\n",
    "               '对话会以视频方式举行，世界经济论坛主席施瓦布主持，全球近600位企业家参加。'])\n",
    "\n",
    "#计算汉字的数量\n",
    "s.str.count('[\\u4e00-\\u9fa5]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "democratic-boundary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#str.contains\n",
    "s = pd.Series(['1232.32', '32123.321', '321323.213', '321321|'])\n",
    "\n",
    "# 检查是否存在非数字或小数点的字符元素\n",
    "s.str.contains('[^\\d.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "round-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-50f51b1205fa>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  pd.to_numeric(s.str.replace('[^\\d.]','')).sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "675999.854"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#str.replace\n",
    "s = pd.Series(['1232.32', '32123.321', '321323.213', '321321|'])\n",
    "\n",
    "# 对原始数据中的非数值或小数点部分进行空字符替换，并转化为数值从而进行计算\n",
    "pd.to_numeric(s.str.replace('[^\\d.]','')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "superb-dover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [国务院总理李克强, 月, 日晚在人民大会堂出席世界经济论坛全球企业家特别对话会]\n",
       "1                            [发表致辞并同企业家代表互动交流]\n",
       "2     [对话会以视频方式举行, 世界经济论坛主席施瓦布主持, 全球近, 位企业家参加]\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#str.findall\n",
    "s = pd.Series(['国务院总理李克强9月15日晚在人民大会堂出席世界经济论坛全球企业家特别对话会，',\n",
    "               '发表致辞并同企业家代表互动交流。',\n",
    "               '对话会以视频方式举行，世界经济论坛主席施瓦布主持，全球近600位企业家参加。'])\n",
    "\n",
    "s.str.findall('[\\u4e00-\\u9fa5]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dressed-tulsa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S</td>\n",
       "      <td>stocks opened up modestly in the green at the ...</td>\n",
       "      <td>as investors wait to hear from Federal Reserve...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dow Jones industrial average was up about ...</td>\n",
       "      <td>or 0.2 percent</td>\n",
       "      <td>at market open</td>\n",
       "      <td>The S&amp;P 500 was up 12 points</td>\n",
       "      <td>or nearly 0.4 percent</td>\n",
       "      <td>while the tech-heavy Nasdaq composite index wa...</td>\n",
       "      <td>or 0.3 percent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Most of the Fed representatives included in We...</td>\n",
       "      <td>The committee is scheduled to offer a monetary...</td>\n",
       "      <td>and Fed Chair Jerome H</td>\n",
       "      <td>Powell will answer questions.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                                                U.S   \n",
       "1  The Dow Jones industrial average was up about ...   \n",
       "2  Most of the Fed representatives included in We...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  stocks opened up modestly in the green at the ...   \n",
       "1                                     or 0.2 percent   \n",
       "2  The committee is scheduled to offer a monetary...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  as investors wait to hear from Federal Reserve...   \n",
       "1                                     at market open   \n",
       "2                             and Fed Chair Jerome H   \n",
       "\n",
       "                               3                      4  \\\n",
       "0                           None                   None   \n",
       "1   The S&P 500 was up 12 points  or nearly 0.4 percent   \n",
       "2  Powell will answer questions.                   None   \n",
       "\n",
       "                                                   5                6  \n",
       "0                                               None             None  \n",
       "1  while the tech-heavy Nasdaq composite index wa...  or 0.3 percent.  \n",
       "2                                               None             None  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#str.split\n",
    "s = pd.Series(['U.S. stocks opened up modestly in the green at the beginning of Wednesday’s trading, as investors wait to hear from Federal Reserve leaders during the afternoon’s committee meeting.',\n",
    "              'The Dow Jones industrial average was up about 55 points, or 0.2 percent, at market open. The S&P 500 was up 12 points, or nearly 0.4 percent, while the tech-heavy Nasdaq composite index was up almost 33 points, or 0.3 percent.',\n",
    "              'Most of the Fed representatives included in Wednesday’s Federal Open Market Committee meeting have spoken publicly about the need for federal aid for Americans struggling during the coronavirus pandemic and recession. The committee is scheduled to offer a monetary policy statement, and Fed Chair Jerome H. Powell will answer questions.'])\n",
    "\n",
    "#英文分句\n",
    "s.str.split('[,.] ')\n",
    "\n",
    "#设置`expand = True`\n",
    "s.str.split('[,.] ',expand = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-instrument",
   "metadata": {},
   "source": [
    "### Day17 练习\n",
    "- 我们将使用到外部文件`ChnSentiCorp_htl_all.csv`，它记录了一些关于酒店的评论数据，请你根据`match_list`中我们所关注的几种对象，在原始数据框`review`列中计算每条评论包含上述对象的总出现次数，并作为新的1列`count`添加到数据框中，最后按照`count`降序排列数据框："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "romance-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./【聚沙成堆-正则表达式】Day17/ChnSentiCorp_htl_all.csv')\n",
    "match_list = ['床', '卫生间', '餐', '服务', '空调']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "palestinian-finland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>0</td>\n",
       "      <td>之前06年的时候入住感觉非常好，服务、硬件都不错。所以这次带父母、亲戚也入住这里，强力推荐了...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>0</td>\n",
       "      <td>我是5/2日入住的该酒店的大床间，优点：酒店周围比较安静，周边环境还可以。缺点：1）酒店比较...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>0</td>\n",
       "      <td>先说说硬件设施。我住的是480元的经济套房，预订时我注明要无烟房。入住1109房间时，让我重...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>1</td>\n",
       "      <td>总的先说一句话，徽商国际大酒店实在是太差！！！服务差！！！饭菜质量差！！！这个月初，我带了一...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>0</td>\n",
       "      <td>不知道前面这位弟兄是不是和我一样住的同一天。我是7.24入住的，25日一早怀着极其极其悲愤的...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>0</td>\n",
       "      <td>淋浴头竟然自己掉了下来，后来修理好了。马桶一直堵。请求修理两次，态度很好，无奈技术不佳，最终...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1</td>\n",
       "      <td>非常好。国内最好的酒店之一。各方面都不错。</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1</td>\n",
       "      <td>经过几次在保定的住宿和其他酒店的比较，发现中银大厦应该是保定最好的酒店了。反正对我来说只要去...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>0</td>\n",
       "      <td>说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7766 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review  count\n",
       "5827      0  之前06年的时候入住感觉非常好，服务、硬件都不错。所以这次带父母、亲戚也入住这里，强力推荐了...   23.0\n",
       "5786      0  我是5/2日入住的该酒店的大床间，优点：酒店周围比较安静，周边环境还可以。缺点：1）酒店比较...   22.0\n",
       "7189      0  先说说硬件设施。我住的是480元的经济套房，预订时我注明要无烟房。入住1109房间时，让我重...   22.0\n",
       "4227      1  总的先说一句话，徽商国际大酒店实在是太差！！！服务差！！！饭菜质量差！！！这个月初，我带了一...   16.0\n",
       "6099      0  不知道前面这位弟兄是不是和我一样住的同一天。我是7.24入住的，25日一早怀着极其极其悲愤的...   16.0\n",
       "...     ...                                                ...    ...\n",
       "7599      0  淋浴头竟然自己掉了下来，后来修理好了。马桶一直堵。请求修理两次，态度很好，无奈技术不佳，最终...    0.0\n",
       "1268      1                              非常好。国内最好的酒店之一。各方面都不错。    0.0\n",
       "557       1  经过几次在保定的住宿和其他酒店的比较，发现中银大厦应该是保定最好的酒店了。反正对我来说只要去...    0.0\n",
       "7765      0  说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...    0.0\n",
       "6374      0                                                NaN    NaN\n",
       "\n",
       "[7766 rows x 3 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['count'] = df.review.str.count('床|卫生间|餐|服务|空调')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "small-chassis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>0</td>\n",
       "      <td>我端午节期间带家人入住了一晚，感觉服务比较差，根本达不到四星的标准，下面我从硬件和服务两方面...</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>0</td>\n",
       "      <td>之前06年的时候入住感觉非常好，服务、硬件都不错。所以这次带父母、亲戚也入住这里，强力推荐了...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7189</th>\n",
       "      <td>0</td>\n",
       "      <td>先说说硬件设施。我住的是480元的经济套房，预订时我注明要无烟房。入住1109房间时，让我重...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>0</td>\n",
       "      <td>我是5/2日入住的该酒店的大床间，优点：酒店周围比较安静，周边环境还可以。缺点：1）酒店比较...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>0</td>\n",
       "      <td>酒店地理位置比较比较偏僻，不过穿过两条马路就是石老人沙滩。酒店前台对客人比较怠慢，特别是女服...</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>1</td>\n",
       "      <td>地理位置不错，房间里设施较旧，属于比较好的三星酒店，基本有准四星的程度</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>1</td>\n",
       "      <td>房间虽小，但很干净的！有点家的感觉，以后还会住！</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>1</td>\n",
       "      <td>入住了一晚.很不错的酒店,不管是环境设施都很不错,特别是客房里的一些小细节,让人住着觉得比较...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>0</td>\n",
       "      <td>说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7766 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review  count\n",
       "7259      0  我端午节期间带家人入住了一晚，感觉服务比较差，根本达不到四星的标准，下面我从硬件和服务两方面...   26.0\n",
       "5827      0  之前06年的时候入住感觉非常好，服务、硬件都不错。所以这次带父母、亲戚也入住这里，强力推荐了...   23.0\n",
       "7189      0  先说说硬件设施。我住的是480元的经济套房，预订时我注明要无烟房。入住1109房间时，让我重...   22.0\n",
       "5786      0  我是5/2日入住的该酒店的大床间，优点：酒店周围比较安静，周边环境还可以。缺点：1）酒店比较...   22.0\n",
       "5663      0  酒店地理位置比较比较偏僻，不过穿过两条马路就是石老人沙滩。酒店前台对客人比较怠慢，特别是女服...   22.0\n",
       "...     ...                                                ...    ...\n",
       "4521      1                地理位置不错，房间里设施较旧，属于比较好的三星酒店，基本有准四星的程度    0.0\n",
       "722       1                           房间虽小，但很干净的！有点家的感觉，以后还会住！    0.0\n",
       "724       1  入住了一晚.很不错的酒店,不管是环境设施都很不错,特别是客房里的一些小细节,让人住着觉得比较...    0.0\n",
       "7765      0  说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...    0.0\n",
       "6374      0                                                NaN    NaN\n",
       "\n",
       "[7766 rows x 3 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='count',ascending = False,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-poison",
   "metadata": {},
   "source": [
    "### Day18 自主练习\n",
    "\n",
    "- **`re.match`**\n",
    "    - 向它传入要匹配的字符串，以及正则表达式，就可以检测这个正则表达式是否匹配字符串。\n",
    "        - 第一个参数：`表达式`\n",
    "        - 第二个参数：`字符串`\n",
    "    - match方法会尝试从字符串的`起始位置`匹配正则表达式\n",
    "        - 如果匹配，返回匹配成功结果\n",
    "        - 如果不匹配，返回None\n",
    "        - **字符串必须从开始就满足正则表达式的要求，否则就匹配失败**\n",
    "    - 多用于在校验填写的数据是否符合要求\n",
    "    - `group`方法：可以输出匹配的内容\n",
    "    - `span`方法：可以输出匹配的范围，结果是(0,25),这就是匹配到的结果字符串在原字符串中的位置范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "proprietary-emergency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "content = 'Hello 123 4567 World_This is a Regex Demo'\n",
    "print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "incredible-republican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 25), match='Hello 123 4567 World_This'>\n",
      "Hello 123 4567 World_This\n",
      "(0, 25)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "^Hello\\s\\d\\d\\d\\s\\d{4}\\s\\w{10}\n",
    "# 开头的 ^ 匹配字符串的开头，也就是以 Hello 开头\n",
    "# \\s 匹配空白字符，用来匹配目标字符串的空格\n",
    "# \\d 匹配数字，3 个 \\d 匹配 123\n",
    "# 再写 1 个 \\s 匹配空格\n",
    "# \\d后面可以跟 {4} 代表匹配前面的规则 4 次，也就是匹配 4 个数字\n",
    "# 后面再紧接 1 个空白字符\n",
    "# 最后\\w{10} 匹配 10 个字母及下划线\n",
    "\n",
    "'''\n",
    "result = re.match('Hello\\s\\d\\d\\d\\s\\d{4}\\s\\w{10}',content)\n",
    "print(result)\n",
    "print(result.group())\n",
    "print(result.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-smart",
   "metadata": {},
   "source": [
    "### Day19 Search方法\n",
    "- 在匹配时会扫描整个字符串，然后返回`第一个成功匹配`的结果\n",
    "- 在匹配时，`search`方法会依次扫描字符串，直到找到第一个符合规则的字符串，然后返回匹配内容，如果搜索完了还没有找到，就返回None\n",
    "    - 对比`findall`方法，它会搜索整个字符串，然后返回匹配正则表达式的所有内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "curious-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''<div id=\"songs-list\">\n",
    "<h2 class=\"title\">经典老歌</h2>\n",
    "<p class=\"introduction\">\n",
    "经典老歌列表\n",
    "</p>\n",
    "<ul id=\"list\" class=\"list-group\">\n",
    "<li data-view=\"2\">一路上有你</li>\n",
    "<li data-view=\"7\">\n",
    "<a href=\"/2.mp3\" singer=\"任贤齐\">沧海一声笑</a>\n",
    "</li>\n",
    "<li data-view=\"4\" class=\"active\">\n",
    "<a href=\"/3.mp3\" singer=\"齐秦\">往事随风</a>\n",
    "</li>\n",
    "<li data-view=\"6\"><a href=\"/4.mp3\" singer=\"beyond\">光辉岁月</a></li>\n",
    "<li data-view=\"5\"><a href=\"/5.mp3\" singer=\"陈慧琳\">记事本</a></li>\n",
    "<li data-view=\"5\">\n",
    "先找规律，ul 节点里有许多 li 节点，其中 li 节点中有的包含 a 节点，有的不包含 a 节点，a 节点\n",
    "还有一些相应的属性 —— 超链接和歌手名。\n",
    "首先，我们尝试提取 class为 active 的 li 节点内部超链接包含的歌手名和歌名，此时需要提取第\n",
    "三个 li 节点下 a 节点的 singer 属性和文本。\n",
    "此时，正则表达式可以用 li 开头，然后寻找一个标志符 active，中间的部分可以用 .*? 来匹配。\n",
    "接下来，要提取 singer 这个属性值，所以还需要写入 singer=\"(.*?)\"，这里需要提取的部分用小\n",
    "括号括起来，以便用 group 方法提取出来，它的两侧边界是双引号。\n",
    "然后还需要匹配 a 节点的文本，其中它的左边界是 >，右边界是 </a>。目标内容依然用 (.*?) 来\n",
    "匹配\n",
    "如果正则表达式不加 active（也就是匹配不带 class 为 active 的节点内容）\n",
    "把 active 标签去掉后，从字符串开头开始搜索，此时符合条件的节点就变成了第二个 li 节点，后\n",
    "面的不再匹配，所以运行结果变成第二个 li 节点中的内容。↓↓↓\n",
    "在上面的两次匹配中，search 方法的第三个参数都加了 re.S，这使得 .*? 可以匹配换行，所以含\n",
    "有换行的 li 节点被匹配到了。如果我们将其去掉，结果变成了第四个 li 节点的内容。这是因为第\n",
    "二个和第三个 li 节点都包含了换行符，去掉 re.S 之后，.*? 已经不能匹配换行符，所以正则表达\n",
    "式不会匹配到第二个和第三个 li 节点，而第四个 li 节点中不包含换行符，所以成功匹配：↓↓↓\n",
    "<a href=\"/6.mp3\" singer=\"邓丽君\">但愿人长久</a>\n",
    "</li>\n",
    "</ul>\n",
    "</div>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "frequent-automation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "齐秦 往事随风\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "尝试提取class为active的li节点内部超链接包含的歌手名和歌名，\n",
    "此时需要提取第三个节点下a节点的singer属性和文本\n",
    "\n",
    "此时，正则表达式可以用li开头，然后寻找一个标识符active，中间的部分用.*?来匹配\n",
    "'''\n",
    "\n",
    "result = re.search('<li.*?active.*?singer=\"(.*?)\">(.*?)</a>',html,re.S)\n",
    "if result:\n",
    "    print(result.group(1),result.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "false-columbus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beyond 光辉岁月\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "如果去掉re.S，则会匹配到第四个li节点\n",
    "因为第二个和第三个li节点都包含了换行符\n",
    "去掉re.S之后，`.*?`已经不能匹配换行符，\n",
    "所以正则表达式不会匹配到第二个和第三个li节点\n",
    "\n",
    "而第四个li节点中不不含换行符，所以可以成功匹配\n",
    "'''\n",
    "result = re.search('<li.*?singer=\"(.*?)\">(.*?)</a>',html)\n",
    "if result:\n",
    "    print(result.group(1),result.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "stuck-firewall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/2.mp3', '任贤齐', '沧海一声笑'),\n",
       " ('/3.mp3', '齐秦', '往事随风'),\n",
       " ('/4.mp3', 'beyond', '光辉岁月'),\n",
       " ('/5.mp3', '陈慧琳', '记事本'),\n",
       " ('/6.mp3', '邓丽君', '但愿人长久')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "如果想获取所有a节点的超链接，歌手和革命，可以将search方法换成findall方法\n",
    "\n",
    "如果有结果反悔的话，就是列表类型，所以需要遍历以下来依次获取每组内容\n",
    "'''\n",
    "results = re.findall('<li.*?href=\"(.*?)\".*?singer=\"(.*?)\">(.*?)</a>',html,re.S)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-graham",
   "metadata": {},
   "source": [
    "### Day20 `compile`方法\n",
    "- 可以将正则字符串编译成正则表达式对象，以便在后面的匹配中复用\n",
    "- `compile`还可以传入修饰符，例如`re.S`等修饰符，这样在search,findall等方法总就不需要再额外传了。\n",
    "- 所以可以说`compile`方法是给正则表达式做了一层封装，以便我们更好地重复利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "provincial-accommodation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2019-12-15 ', '2019-12-17 ', '2019-12-22 ')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "有三个日期，想分别将3个日期中的时间去掉，这时可以借助`sub`的方法\n",
    "\n",
    "但是没有必须重复写三个同样的正则表达式，\n",
    "此时可以借助compile方法将正则表达式编译成一个正则表达式对象\n",
    "以便重复使用\n",
    "'''\n",
    "content1 = '2019-12-15 12:00'\n",
    "content2 = '2019-12-17 12:55'\n",
    "content3 = '2019-12-22 13:21'\n",
    "pattern = re.compile('\\d{2}:\\d{2}')\n",
    "\n",
    "result1 = re.sub(pattern,'',content1)\n",
    "result2 = re.sub(pattern,'',content2)\n",
    "result3 = re.sub(pattern,'',content3)\n",
    "\n",
    "result1,result2,result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-criticism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
